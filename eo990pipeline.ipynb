{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMc5AplyYKfLiZpH0WdL6z1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dave-killough/eo990pipeline/blob/main/eo990pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Databricks Pipeline in Colab\n",
        "This notebook is a local development environment for code that will also run in Databricks.  The table of contents on the left can be used as an index for each step in the pipeline.  \n"
      ],
      "metadata": {
        "id": "hglIckLxMFIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Nq9ZmPhqmSqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9d0zNVuXBZr"
      },
      "outputs": [],
      "source": [
        "%pip install pyspark==3.5.0 delta-spark==3.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Ingest CSV"
      ],
      "metadata": {
        "id": "3f_yAHngLy77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EO 990 Ingest CSV\n",
        "import requests\n",
        "import logging\n",
        "import os\n",
        "\n",
        "if 'DATABRICKS_RUNTIME_VERSION' in os.environ:\n",
        "    dbfs = \"/dbfs\"\n",
        "    folder_out = \"/mnt/eo990pipeline\"\n",
        "else: # local setup - no cluster charges!!\n",
        "    dbfs = \"\"\n",
        "    folder_out = \".\"\n",
        "\n",
        "logging.basicConfig(level=logging.INFO) # Initialize logging\n",
        "logger = logging.getLogger(\"EO-990-Ingest-Master\")\n",
        "\n",
        "def ingest(url, filename=None):\n",
        "    if filename is None:\n",
        "        filename = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "    response = requests.get(url) # Download CSV file\n",
        "    if response.status_code == 200:\n",
        "        with open(f\"{dbfs}{folder_out}/{filename}\", \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        logger.info(f\"Successfully downloaded {url}\")\n",
        "    else:\n",
        "        logger.error(f\"Failed to download {url}\")\n",
        "\n",
        "eo_urls = [\n",
        "    \"https://www.irs.gov/pub/irs-soi/eo1.csv\",\n",
        "    \"https://www.irs.gov/pub/irs-soi/eo2.csv\",\n",
        "    \"https://www.irs.gov/pub/irs-soi/eo3.csv\",\n",
        "    \"https://www.irs.gov/pub/irs-soi/eo4.csv\"\n",
        "]\n",
        "for url in eo_urls:\n",
        "    ingest(url)\n",
        "bucket = \"https://storage.googleapis.com/benevolentmachines\"\n",
        "ingest(f\"{bucket}/e990_extract.csv\", \"eo990extract.csv\")\n",
        "ingest(f\"{bucket}/gcst.csv\")\n",
        "# end"
      ],
      "metadata": {
        "id": "WDJ8KMxgLaFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Prepare E990"
      ],
      "metadata": {
        "id": "FT_hl3AGQNz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EO 990 Prepare E990\n",
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "appName = \"eo990-prepare-e990\"\n",
        "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
        "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
        "    folder_in = \"/mnt/eo990pipeline\"\n",
        "else: # local spark - no cluster charges!!\n",
        "    folder_in = \".\"\n",
        "\n",
        "from pyspark.sql.types import \\\n",
        "    StructType, StructField, StringType, IntegerType, LongType\n",
        "schema = StructType([\n",
        "    StructField(\"BLOBI\", StringType(), True),\n",
        "    StructField(\"EIN\", StringType(), True),\n",
        "    StructField(\"ReturnTypeCd\", StringType(), True),\n",
        "    StructField(\"TaxPeriodEndDt\", StringType(), True),\n",
        "    StructField(\"BusinessName\", StringType(), True),\n",
        "    StructField(\"BusinessStreet\", StringType(), True),\n",
        "    StructField(\"CityNm\", StringType(), True),\n",
        "    StructField(\"StateAbbreviationCd\", StringType(), True),\n",
        "    StructField(\"ZIPCd\", StringType(), True),\n",
        "    StructField(\"WebsiteAddressTxt\", StringType(), True),\n",
        "    StructField(\"TotalEmployeeCnt\", IntegerType(), True),\n",
        "    StructField(\"TotalVolunteersCnt\", IntegerType(), True),\n",
        "    StructField(\"GrossReceiptsAmt\", LongType(), True),\n",
        "    StructField(\"PYContributionsGrantsAmt\", LongType(), True),\n",
        "    StructField(\"CYContributionsGrantsAmt\", LongType(), True),\n",
        "    StructField(\"PYProgramServiceRevenueAmt\", LongType(), True),\n",
        "    StructField(\"CYProgramServiceRevenueAmt\", LongType(), True),\n",
        "    StructField(\"PYInvestmentIncomeAmt\", LongType(), True),\n",
        "    StructField(\"CYInvestmentIncomeAmt\", LongType(), True),\n",
        "    StructField(\"PYOtherRevenueAmt\", LongType(), True),\n",
        "    StructField(\"CYOtherRevenueAmt\", LongType(), True),\n",
        "    StructField(\"PYTotalRevenueAmt\", LongType(), True),\n",
        "    StructField(\"CYTotalRevenueAmt\", LongType(), True),\n",
        "    StructField(\"PYGrantsAndSimilarPaidAmt\", LongType(), True),\n",
        "    StructField(\"CYGrantsAndSimilarPaidAmt\", LongType(), True),\n",
        "    StructField(\"PYBenefitsPaidToMembersAmt\", LongType(), True),\n",
        "    StructField(\"CYBenefitsPaidToMembersAmt\", LongType(), True),\n",
        "    StructField(\"PYSalariesCompEmpBnftPaidAmt\", LongType(), True),\n",
        "    StructField(\"CYSalariesCompEmpBnftPaidAmt\", LongType(), True),\n",
        "    StructField(\"PYTotalProfFndrsngExpnsAmt\", LongType(), True),\n",
        "    StructField(\"CYTotalProfFndrsngExpnsAmt\", LongType(), True),\n",
        "    StructField(\"CYTotalFundraisingExpenseAmt\", LongType(), True),\n",
        "    StructField(\"PYOtherExpensesAmt\", LongType(), True),\n",
        "    StructField(\"CYOtherExpensesAmt\", LongType(), True),\n",
        "    StructField(\"PYTotalExpensesAmt\", LongType(), True),\n",
        "    StructField(\"CYTotalExpensesAmt\", LongType(), True),\n",
        "    StructField(\"PYRevenuesLessExpensesAmt\", LongType(), True),\n",
        "    StructField(\"CYRevenuesLessExpensesAmt\", LongType(), True),\n",
        "    StructField(\"TotalAssetsBOYAmt\", LongType(), True),\n",
        "    StructField(\"TotalAssetsEOYAmt\", LongType(), True),\n",
        "    StructField(\"TotalLiabilitiesBOYAmt\", LongType(), True),\n",
        "    StructField(\"TotalLiabilitiesEOYAmt\", LongType(), True),\n",
        "    StructField(\"NetAssetsOrFundBalancesBOYAmt\", LongType(), True),\n",
        "    StructField(\"NetAssetsOrFundBalancesEOYAmt\", LongType(), True),\n",
        "    StructField(\"ActivityOrMissionDesc\", StringType(), True)\n",
        "])\n",
        "\n",
        "e990_df = spark.read.format(\"csv\") \\\n",
        "    .option(\"delimiter\", \"|\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(schema) \\\n",
        "    .load(f\"{folder_in}/eo990extract.csv\")\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS e990\") # make repeatable\n",
        "e990_df.write.saveAsTable('e990')\n",
        "# end"
      ],
      "metadata": {
        "id": "vnyvwloaP1I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Prepare EOMF"
      ],
      "metadata": {
        "id": "GGjaY1OJYVxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EO 990 Prepare EOMF\n",
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "appName = \"eo990-prepare-eomf\"\n",
        "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
        "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
        "    folder_in = \"/mnt/eo990pipeline\"\n",
        "else: # local spark - no cluster charges!!\n",
        "    folder_in = \".\"\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
        "schema = StructType([\n",
        "    StructField(\"EIN\", StringType(), True),\n",
        "    StructField(\"NAME\", StringType(), True),\n",
        "    StructField(\"ICO\", StringType(), True),\n",
        "    StructField(\"STREET\", StringType(), True),\n",
        "    StructField(\"CITY\", StringType(), True),\n",
        "    StructField(\"STATE\", StringType(), True),\n",
        "    StructField(\"ZIP\", StringType(), True),\n",
        "    StructField(\"RULING\", StringType(), True),\n",
        "    StructField(\"TAX_PERIOD\", StringType(), True),\n",
        "    StructField(\"GROUP\", StringType(), True),\n",
        "    StructField(\"SUBSECTION\", StringType(), True),\n",
        "    StructField(\"AFFILIATION\", StringType(), True),\n",
        "    StructField(\"CLASSIFICATION\", StringType(), True),\n",
        "    StructField(\"DEDUCTIBILITY\", StringType(), True),\n",
        "    StructField(\"FOUNDATION\", StringType(), True),\n",
        "    StructField(\"ACTIVITY\", StringType(), True),\n",
        "    StructField(\"ORGANIZATION\", StringType(), True),\n",
        "    StructField(\"STATUS\", StringType(), True),\n",
        "    StructField(\"ASSET_CD\", StringType(), True),\n",
        "    StructField(\"INCOME_CD\", StringType(), True),\n",
        "    StructField(\"FILING_REQ_CD\", StringType(), True),\n",
        "    StructField(\"PF_FILING_REQ_CD\", StringType(), True),\n",
        "    StructField(\"ACCT_PD\", StringType(), True),\n",
        "    StructField(\"ASSET_AMT\", LongType(), True),\n",
        "    StructField(\"INCOME_AMT\", LongType(), True),\n",
        "    StructField(\"REVENUE_AMT\", LongType(), True),\n",
        "    StructField(\"NTEE_CD\", StringType(), True),\n",
        "    StructField(\"SORT_NAME\", StringType(), True)\n",
        "])\n",
        "\n",
        "eomf_df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(schema) \\\n",
        "    .load(f\"{folder_in}/eo[1234].csv\") # Concatenate input files - yes!\n",
        "\n",
        "from pyspark.sql.functions import col, substring\n",
        "eomf_df = eomf_df.fillna({'NTEE_CD': 'Z99'})\n",
        "eomf_df = eomf_df.withColumn(\"NTEE3\", substring(col(\"NTEE_CD\"), 1, 3))\n",
        "eomf_df = eomf_df.withColumnRenamed(\"GROUP\", \"GROUP_NUM\") # GROUP is reserved\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS eomf\")\n",
        "eomf_df.write.saveAsTable('eomf')\n",
        "# end"
      ],
      "metadata": {
        "id": "LlE2EvzbYWLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Prepare GCST"
      ],
      "metadata": {
        "id": "zJcl5YqKogKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EO 990 Prepare GCST\n",
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "appName = \"eo990-prepare-gcst\"\n",
        "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
        "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
        "    folder_in = \"/mnt/eo990pipeline\"\n",
        "else: # local spark - no cluster charges!!\n",
        "    folder_in = \".\"\n",
        "\n",
        "from pyspark.sql.types import \\\n",
        "    StructType, StructField, StringType, IntegerType, LongType\n",
        "schema = StructType([\n",
        "    StructField(\"code\", StringType(), True),\n",
        "    StructField(\"desc\", StringType(), True),\n",
        "])\n",
        "gcst_df = spark.read.format(\"csv\") \\\n",
        "    .option(\"delimiter\", \"|\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(schema) \\\n",
        "    .load(f\"{folder_in}/gcst.csv\")\n",
        "gcst_df = gcst_df.withColumnRenamed(\"desc\", \"SECTOR\") # desc is reserved in SQL\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS gcst\")\n",
        "gcst_df.write.saveAsTable('gcst')"
      ],
      "metadata": {
        "id": "QlQVVzRkofQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Transform"
      ],
      "metadata": {
        "id": "R-bN2b9Pqu1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EO 990 Transform\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"eo990-transform\").getOrCreate()\n",
        "eo990_df = spark.sql(\"\"\"\n",
        "SELECT\n",
        "    eomf.EIN, eomf.NAME, eomf.ICO, eomf.STREET, eomf.CITY, eomf.STATE, eomf.ZIP,\n",
        "    eomf.RULING, eomf.TAX_PERIOD, eomf.GROUP_NUM, eomf.SUBSECTION,\n",
        "    eomf.AFFILIATION, eomf.CLASSIFICATION, eomf.DEDUCTIBILITY, eomf.FOUNDATION,\n",
        "    eomf.ACTIVITY, eomf.ORGANIZATION, eomf.STATUS, eomf.ASSET_CD,\n",
        "    eomf.INCOME_CD, eomf.FILING_REQ_CD, eomf.PF_FILING_REQ_CD, eomf.ACCT_PD,\n",
        "    eomf.ASSET_AMT, eomf.INCOME_AMT, eomf.REVENUE_AMT, eomf.NTEE_CD,\n",
        "    eomf.SORT_NAME, eomf.NTEE3, gcst.SECTOR,\n",
        "    e990.BLOBI, e990.ReturnTypeCd, e990.TaxPeriodEndDt, e990.BusinessName,\n",
        "    e990.BusinessStreet, e990.CityNm, e990.StateAbbreviationCd, e990.ZIPCd,\n",
        "    e990.WebsiteAddressTxt, e990.TotalEmployeeCnt, e990.TotalVolunteersCnt,\n",
        "    e990.GrossReceiptsAmt,\n",
        "    e990.PYContributionsGrantsAmt, e990.CYContributionsGrantsAmt,\n",
        "    e990.PYProgramServiceRevenueAmt, e990.CYProgramServiceRevenueAmt,\n",
        "    e990.PYInvestmentIncomeAmt, e990.CYInvestmentIncomeAmt,\n",
        "    e990.PYOtherRevenueAmt, e990.CYOtherRevenueAmt,\n",
        "    e990.PYTotalRevenueAmt, e990.CYTotalRevenueAmt,\n",
        "    e990.PYGrantsAndSimilarPaidAmt, e990.CYGrantsAndSimilarPaidAmt,\n",
        "    e990.PYBenefitsPaidToMembersAmt, e990.CYBenefitsPaidToMembersAmt,\n",
        "    e990.PYSalariesCompEmpBnftPaidAmt, e990.CYSalariesCompEmpBnftPaidAmt,\n",
        "    e990.PYTotalProfFndrsngExpnsAmt, e990.CYTotalProfFndrsngExpnsAmt,\n",
        "    e990.CYTotalFundraisingExpenseAmt,\n",
        "    e990.PYOtherExpensesAmt, e990.CYOtherExpensesAmt,\n",
        "    e990.PYTotalExpensesAmt, e990.CYTotalExpensesAmt,\n",
        "    e990.PYRevenuesLessExpensesAmt, e990.CYRevenuesLessExpensesAmt,\n",
        "    e990.TotalAssetsBOYAmt, e990.TotalAssetsEOYAmt,\n",
        "    e990.TotalLiabilitiesBOYAmt, e990.TotalLiabilitiesEOYAmt,\n",
        "    e990.NetAssetsOrFundBalancesBOYAmt, e990.NetAssetsOrFundBalancesEOYAmt,\n",
        "    e990.ActivityOrMissionDesc\n",
        "FROM eomf\n",
        "INNER JOIN e990 ON eomf.EIN = e990.EIN\n",
        "LEFT JOIN gcst ON eomf.NTEE3 = gcst.code\n",
        "\"\"\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS eo990\")\n",
        "eo990_df.write.saveAsTable('eo990')"
      ],
      "metadata": {
        "id": "fiLbZyGgqP0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Learn"
      ],
      "metadata": {
        "id": "D8jikI3cynku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EO 990 Learn\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import log, col\n",
        "from pyspark.sql.functions import col, lit\n",
        "from pyspark.sql.window import Window\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Launch the awesome Spark Engine!!\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"eo990-cluster-simple\") \\\n",
        "    .config(\"spark.databricks.photon.enabled\", \"false\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# The objective is a Kmeans clustering of public US tax exempt organizations\n",
        "# based the employee count, volunteer count, and contribution/grant amount\n",
        "# recorded in their most recent 990 filing. We start by selecting the data:\n",
        "\n",
        "df = spark.sql(\"\"\"\n",
        "    SELECT eo990.EIN, eo990.CYContributionsGrantsAmt,\n",
        "           eo990.TotalEmployeeCnt, eo990.TotalVolunteersCnt\n",
        "    FROM eo990\n",
        "    WHERE TotalVolunteersCnt < 1000000\n",
        "    AND TotalEmployeeCnt > 0\n",
        "    AND TotalVolunteersCnt > 0\n",
        "    AND CYContributionsGrantsAmt > 0\n",
        "\"\"\")\n",
        "\n",
        "# All of these features exhibit a long-tailed distribution of values; the\n",
        "# larger the values, the less frequently they occur. As with most machine\n",
        "# learning tasks, a more uniform distribution is needed for the algorithm\n",
        "# to function effectively. A log transformation is applied to acheive this\n",
        "\n",
        "df_transformed = df.withColumn(\n",
        "    \"log_CYContributionsGrantsAmt\", log(col(\"CYContributionsGrantsAmt\") + 1))\n",
        "df_transformed = df_transformed.withColumn(\n",
        "    \"log_TotalEmployeeCnt\", log(col(\"TotalEmployeeCnt\") + 1))\n",
        "df_transformed = df_transformed.withColumn(\n",
        "    \"log_TotalVolunteersCnt\", log(col(\"TotalVolunteersCnt\") + 1))\n",
        "\n",
        "# Null values and outliers are removed:\n",
        "\n",
        "df_transformed = df_transformed.dropna()\n",
        "bounds = {\n",
        "    c: dict(\n",
        "        zip([\"q1\", \"q3\"], df_transformed.approxQuantile(c, [0.25, 0.75], 0))\n",
        "    )\n",
        "    for c in [\"log_CYContributionsGrantsAmt\",\n",
        "              \"log_TotalEmployeeCnt\", \"log_TotalVolunteersCnt\"]\n",
        "}\n",
        "for c in bounds:\n",
        "    iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
        "    bounds[c]['lower_bound'] = bounds[c]['q1'] - (1.5 * iqr)\n",
        "    bounds[c]['upper_bound'] = bounds[c]['q3'] + (1.5 * iqr)\n",
        "for c in bounds:\n",
        "    df_transformed = df_transformed.filter(\n",
        "        (col(c) >= bounds[c]['lower_bound']) &\n",
        "        (col(c) <= bounds[c]['upper_bound'])\n",
        "    )\n",
        "\n",
        "# A pipeline assembling the features into a vector is contructed with\n",
        "# a standard scaler.\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"log_CYContributionsGrantsAmt\",\n",
        "               \"log_TotalEmployeeCnt\", \"log_TotalVolunteersCnt\"],\n",
        "    outputCol=\"features\")\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "pipeline = Pipeline(stages=[assembler, scaler])\n",
        "pipelineModel = pipeline.fit(df_transformed)\n",
        "df_kmeans_ready = pipelineModel.transform(df_transformed)\n",
        "\n",
        "# A KMeans function is setup and invoked, and the counts for each K value\n",
        "# are displayed\n",
        "\n",
        "def apply_kmeans(df, k):\n",
        "    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"scaledFeatures\")\n",
        "    model = kmeans.fit(df)\n",
        "    return model.transform(df)\n",
        "sample = df_kmeans_ready.sample(withReplacement=False, fraction=1.0, seed=1)\n",
        "eo990clustering_df = apply_kmeans(sample, 4)\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS eo990clustering\")\n",
        "eo990clustering_df.write.saveAsTable('eo990clustering')"
      ],
      "metadata": {
        "id": "1pKmkTP9tNfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EO 990 Hydrate"
      ],
      "metadata": {
        "id": "mdfI9GSmSZJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "import plotly.express as px\n",
        "\n",
        "appName = \"eo990-hydrate\"\n",
        "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
        "\n",
        "if 'DATABRICKS_RUNTIME_VERSION' in os.environ:\n",
        "    dbfs = \"/dbfs\"\n",
        "    folder_out = \"/mnt/eo990pipeline\"\n",
        "else: # local setup - no cluster charges!!\n",
        "    dbfs = \"\"\n",
        "    folder_out = \".\"\n",
        "\n",
        "hydrate_df = spark.sql(\"\"\"\n",
        "    SELECT CYContributionsGrantsAmt AS ContributionsGrants,\n",
        "         TotalEmployeeCnt AS Employees,\n",
        "         TotalVolunteersCnt AS Volunteers,\n",
        "         CAST(prediction AS STRING) AS Cluster\n",
        "    FROM eo990clustering\n",
        "\"\"\")\n",
        "subset_df = hydrate_df.sample(\n",
        "    withReplacement=False, fraction=0.5, seed=1)\n",
        "pdf = subset_df.toPandas()\n",
        "color_map = {\n",
        "    '0': '#1ac958',  # green\n",
        "    '1': '#db5d51',  # red\n",
        "    '2': '#fac828',  # gold\n",
        "    '3': '#5385f4',  # blue\n",
        "}\n",
        "fig = px.scatter_3d(\n",
        "    pdf,\n",
        "    x='ContributionsGrants',\n",
        "    y='Employees',\n",
        "    z='Volunteers',\n",
        "    color='Cluster',color_discrete_map=color_map,\n",
        "    title='Exempt Organization Kmeans Clustering K=4')\n",
        "fig.write_html(f'{dbfs}{folder_out}/clustering.html', include_plotlyjs='cdn')\n",
        "\n",
        "# and that ends the pipeline!\n",
        "\n",
        "fig.show() # can be commented out in production"
      ],
      "metadata": {
        "id": "yWeVaSHBvfoQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}